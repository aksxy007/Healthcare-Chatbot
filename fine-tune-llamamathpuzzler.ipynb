{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:58:15.840437Z","iopub.execute_input":"2025-01-26T16:58:15.840704Z","iopub.status.idle":"2025-01-26T16:59:03.385482Z","shell.execute_reply.started":"2025-01-26T16:58:15.840685Z","shell.execute_reply":"2025-01-26T16:59:03.384561Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"%pip install unsloth \"xformers==0.0.28.post2\" \n%pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"git+https://github.com/unslothai/unsloth.git\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:59:03.386758Z","iopub.execute_input":"2025-01-26T16:59:03.387071Z","iopub.status.idle":"2025-01-26T17:01:49.493418Z","shell.execute_reply.started":"2025-01-26T16:59:03.387031Z","shell.execute_reply":"2025-01-26T17:01:49.492382Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.1.6-py3-none-any.whl.metadata (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting xformers==0.0.28.post2\n  Downloading xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.28.post2) (1.26.4)\nCollecting torch==2.5.0 (from xformers==0.0.28.post2)\n  Downloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (2024.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.1.0 (from torch==2.5.0->xformers==0.0.28.post2)\n  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.0->xformers==0.0.28.post2) (1.3.0)\nCollecting unsloth_zoo>=2025.1.4 (from unsloth)\n  Downloading unsloth_zoo-2025.1.5-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.13-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: transformers!=4.47.0,>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.48.1)\nRequirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.3.0)\nRequirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.13.0)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.27.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28.post2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28.post2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28.post2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28.post2) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28.post2) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->xformers==0.0.28.post2) (2.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.1.4->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.1.4->unsloth) (11.0.0)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.12.14)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.0->xformers==0.0.28.post2) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->xformers==0.0.28.post2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->xformers==0.0.28.post2) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->xformers==0.0.28.post2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->xformers==0.0.28.post2) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->xformers==0.0.28.post2) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\nDownloading xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading unsloth-2025.1.6-py3-none-any.whl (175 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/175.5 kB\u001b[0m \u001b[31m206.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.1.5-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.9.13-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nInstalling collected packages: triton, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, xformers, unsloth_zoo, unsloth\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 24.12.1 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.5.0 which is incompatible.\ntorchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cut_cross_entropy-25.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 shtab-1.7.1 torch-2.5.0 triton-3.1.0 tyro-0.9.13 unsloth-2025.1.6 unsloth_zoo-2025.1.5 xformers-0.0.28.post2\nNote: you may need to restart the kernel to use updated packages.\nFound existing installation: unsloth 2025.1.6\nUninstalling unsloth-2025.1.6:\n  Successfully uninstalled unsloth-2025.1.6\nCollecting git+https://github.com/unslothai/unsloth.git\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-req-build-jdjhxafa\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-req-build-jdjhxafa\n  Resolved https://github.com/unslothai/unsloth.git to commit 1ef71e8b9c570d59470ba5a40ed49064db295f43\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for unsloth: filename=unsloth-2025.1.7-py3-none-any.whl size=174898 sha256=c816f7c7265d52fabde9cfba3504f1fe84dc9514cbe8c43dadb20a8cce0a5a99\n  Stored in directory: /tmp/pip-ephem-wheel-cache-18kfx1f_/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth\nSuccessfully installed unsloth-2025.1.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from datasets import Dataset,load_dataset,DatasetDict,load_from_disk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T17:01:49.495317Z","iopub.execute_input":"2025-01-26T17:01:49.495627Z","iopub.status.idle":"2025-01-26T17:01:51.383000Z","shell.execute_reply.started":"2025-01-26T17:01:49.495592Z","shell.execute_reply":"2025-01-26T17:01:51.382124Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n    max_seq_length = 2048,\n    dtype = torch.float16,\n    load_in_4bit = True,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T18:04:13.368588Z","iopub.execute_input":"2025-01-26T18:04:13.368895Z","iopub.status.idle":"2025-01-26T18:04:20.793295Z","shell.execute_reply.started":"2025-01-26T18:04:13.368870Z","shell.execute_reply":"2025-01-26T18:04:20.792410Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.1.7: Fast Llama patching. Transformers: 4.48.1.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, \n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, \n    bias = \"none\",   \n    use_gradient_checkpointing = \"unsloth\", \n    random_state = 3407,\n    use_rslora = False,  \n    loftq_config = None, \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T18:04:33.105977Z","iopub.execute_input":"2025-01-26T18:04:33.106280Z","iopub.status.idle":"2025-01-26T18:04:33.113147Z","shell.execute_reply.started":"2025-01-26T18:04:33.106256Z","shell.execute_reply":"2025-01-26T18:04:33.112257Z"}},"outputs":[{"name":"stderr","text":"Unsloth: Already have LoRA adapters! We shall skip this step.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"dataset = load_dataset(\"Atharva26/Math-Dial-conversations-dataset\",split=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T17:03:21.056351Z","iopub.execute_input":"2025-01-26T17:03:21.056645Z","iopub.status.idle":"2025-01-26T17:03:23.145878Z","shell.execute_reply.started":"2025-01-26T17:03:21.056615Z","shell.execute_reply":"2025-01-26T17:03:23.145069Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/352 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba77f0e1e764694ad245d90c61a5e8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/2.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab3b982970c14ec292b569bf9d3c5d92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2262 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30c743a04aae4798a9dea57e2e68545b"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T17:03:23.146817Z","iopub.execute_input":"2025-01-26T17:03:23.147154Z","iopub.status.idle":"2025-01-26T17:03:23.538058Z","shell.execute_reply.started":"2025-01-26T17:03:23.147120Z","shell.execute_reply":"2025-01-26T17:03:23.537095Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['conversations'],\n        num_rows: 2262\n    })\n})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from unsloth.chat_templates import standardize_sharegpt,get_chat_template\n\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"llama-3.1\",\n)\n\ndef formatting_prompts_func(examples):\n    convos = examples[\"conversations\"]\n    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n    return { \"text\" : texts, }\n\n# dataset = standardize_sharegpt(dataset)\ndataset = dataset.map(formatting_prompts_func, batched = True,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T17:03:23.540255Z","iopub.execute_input":"2025-01-26T17:03:23.540541Z","iopub.status.idle":"2025-01-26T17:03:24.231876Z","shell.execute_reply.started":"2025-01-26T17:03:23.540512Z","shell.execute_reply":"2025-01-26T17:03:24.230587Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2262 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53bffaa61f3c45bd95115259bb9d1547"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"train_test_split = dataset['train'].train_test_split(test_size=0.2)  # 90% train, 10% test\ntrain_dataset = train_test_split['train']\ntest_dataset = train_test_split['test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T17:03:24.233196Z","iopub.execute_input":"2025-01-26T17:03:24.233912Z","iopub.status.idle":"2025-01-26T17:03:24.249560Z","shell.execute_reply.started":"2025-01-26T17:03:24.233693Z","shell.execute_reply":"2025-01-26T17:03:24.248789Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_dataset['text'][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T17:05:17.127464Z","iopub.execute_input":"2025-01-26T17:05:17.127747Z","iopub.status.idle":"2025-01-26T17:05:17.148975Z","shell.execute_reply.started":"2025-01-26T17:05:17.127726Z","shell.execute_reply":"2025-01-26T17:05:17.148141Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\nYou are a helpful Mathematics Professor for 7th grade students. Your job is to give hints and help students get to the right answer without revealing the answer directly. Help the student get to the solution for the given question: Steve's new book sells 1,000,000 copies.  He got an advance to pay for 100,000 copies. He gets $2 for each copy of the book sold.  His agent takes 10% of that.  How much money did he keep not counting the money from the advance?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nSteve sells 1,000,000 - 100,000 = 900,000 copies of the book.\\nHe earns $2 x 0.9 = $1.8 for each book sold.\\nSo he earned a total of $1.8 x 900,000 = $1,620,000.\\nHis agent takes 10% of that, which is $162,000.\\nTherefore, Steve kept $1,620,000 - $162,000 = $1,458,000 not counting the money from the advance.\\n 1,458,000<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nho how have you solved this?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nI calculated the total amount of money earned by Steve from the book sales (1,000,000 - 100,000 = 900,000 copies x $2 = $1,620,000). Then I subtracted the 10% agent fee ($162,000) to get the total amount of money kept by Steve not counting the money from the advance ($1,620,000 - $162,000 = $1,458,000).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nyou don't count the money from the advance so?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThat's right. I didn't count the money from the advance because it was already paid out before the book sales.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nso why did you remove 162,000? from youw sum?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nI removed 162,000 from the total amount of money earned by Steve because that is the amount of money taken by his agent as a fee (10% of the total earnings).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n20 * 4 =?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n20 * 4 = 80<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nuse this to help you 1.8 x 900,000 =?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n1.8 x 900,000 = 1,620,000<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nno that is incorrect use a calculator please?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n1.8 x 900,000 = 1,620,000 (using calculator).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nno of copies originally =?  - the advance =?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n1,000,000 - 100,000 = 900,000 copies of the book.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nplease times that figure by how much he gets for each book which is?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n900,000 copies x $2 = $1,620,000.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nno that is incorrect what is double 900,000?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nDouble 900,000 is 1,800,000.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n1,800,000 - 10 per cent commision =?<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n1,800,000 - 10% = 1,620,000.<|eot_id|>\""},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments, DataCollatorForSeq2Seq\nfrom unsloth import is_bfloat16_supported\nfrom unsloth.chat_templates import train_on_responses_only\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=2048,\n    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n    dataset_num_proc=2,\n    packing=False,\n    args=TrainingArguments(\n        per_device_train_batch_size=2,\n        per_device_eval_batch_size=2,\n        gradient_accumulation_steps=4,\n        warmup_steps=5,\n        max_steps=160,\n        eval_strategy=\"steps\",\n        eval_steps=10,\n        learning_rate=2e-5,\n        fp16=not is_bfloat16_supported(),\n        bf16=is_bfloat16_supported(),\n        logging_steps=1,\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",\n        seed=3407,\n        output_dir=\"outputs\",\n        report_to=\"none\",\n    ),\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T18:04:41.343345Z","iopub.execute_input":"2025-01-26T18:04:41.343672Z","iopub.status.idle":"2025-01-26T18:04:47.981557Z","shell.execute_reply.started":"2025-01-26T18:04:41.343643Z","shell.execute_reply":"2025-01-26T18:04:47.980531Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/1809 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecf8dbd3bd764b7bad26269b1c8ae6d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d385e2a288eb4713841f3401f5bcb3dc"}},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"trainer = train_on_responses_only(\n    trainer,\n    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n)\n\ntrainer_stats = trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T18:04:48.864902Z","iopub.execute_input":"2025-01-26T18:04:48.865212Z","iopub.status.idle":"2025-01-26T19:13:00.696516Z","shell.execute_reply.started":"2025-01-26T18:04:48.865183Z","shell.execute_reply":"2025-01-26T19:13:00.695723Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1809 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce765f6653e54121852b0c7525f0854d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aa8a3590e3a4f0ebbfd7f8b481b27b3"}},"metadata":{}},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 1,809 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 160\n \"-____-\"     Number of trainable parameters = 24,313,856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [160/160 1:07:56, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.360300</td>\n      <td>2.414129</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.928800</td>\n      <td>2.111485</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.016200</td>\n      <td>1.987738</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.802300</td>\n      <td>1.933712</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.784300</td>\n      <td>1.886228</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.611800</td>\n      <td>1.850416</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.764100</td>\n      <td>1.825466</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.750300</td>\n      <td>1.806680</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.825200</td>\n      <td>1.792102</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.007700</td>\n      <td>1.781394</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.716000</td>\n      <td>1.773046</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.668000</td>\n      <td>1.765699</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.974700</td>\n      <td>1.760743</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.758200</td>\n      <td>1.757351</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.929800</td>\n      <td>1.755506</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.767100</td>\n      <td>1.754899</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"model.save_pretrained(\"llama_3b_math_puzzle_tutor\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T19:26:58.172623Z","iopub.execute_input":"2025-01-26T19:26:58.172982Z","iopub.status.idle":"2025-01-26T19:26:58.735733Z","shell.execute_reply.started":"2025-01-26T19:26:58.172952Z","shell.execute_reply":"2025-01-26T19:26:58.735075Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"tokenizer.save_pretrained(\"llama_3b_math_puzzle_tutor\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T19:26:59.865725Z","iopub.execute_input":"2025-01-26T19:26:59.866066Z","iopub.status.idle":"2025-01-26T19:27:00.091471Z","shell.execute_reply.started":"2025-01-26T19:26:59.866039Z","shell.execute_reply":"2025-01-26T19:27:00.090439Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"('llama_3b_math_puzzle_tutor/tokenizer_config.json',\n 'llama_3b_math_puzzle_tutor/special_tokens_map.json',\n 'llama_3b_math_puzzle_tutor/tokenizer.json')"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"# from unsloth.chat_templates import get_chat_template\n\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"llama-3.1\",\n)\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\ninstruction_prompt = \"You are a helpful Mathematics Professor for 7th grade students. Your job is to give hints through other example and help students get to the right answer without revealing the answer directly. Help the student get to the solution for the given question: \"\n\nquestion = \"\"\"\nA rectangle has a length of 12 cm and a width of 8 cm.\nIf you increase both the length and width by 3 cm, what will be the new area of the rectangle?\nCalculate the original area and the new area.\nHow much does the area increase?\"\"\"\n\ninstruction =  f\"{instruction_prompt}\"\nmessages = [{\"role\": \"system\", \"content\": instruction}]\n\nwhile True:\n    student = input(\"Student: \")\n    if student == \"\":\n        break\n    messages.append({\"role\":\"user\",\"content\":student})\n    inputs = tokenizer.apply_chat_template(\n        messages,\n        tokenize = True,\n        add_generation_prompt = True, # Must add for generation\n        return_tensors = \"pt\",\n    ).to(\"cuda\")\n    \n    outputs = model.generate(input_ids = inputs, max_new_tokens = 512, use_cache = True,\n                             temperature = 1.5, min_p = 0.1)\n    response=tokenizer.batch_decode(outputs,skip_special_tokens=True)\n    # print(response)\n    if \"assistant\" in response[0]:\n        assistant_response = response[0].split(\"assistant\")[-1].strip()\n    else:\n        assistant_response = response[0].strip()\n\n    print(\"Tutor: \",assistant_response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T19:19:12.313684Z","iopub.execute_input":"2025-01-26T19:19:12.314002Z","iopub.status.idle":"2025-01-26T19:26:52.769379Z","shell.execute_reply.started":"2025-01-26T19:19:12.313976Z","shell.execute_reply":"2025-01-26T19:26:52.768560Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Student:  Hi A rectangle has a length of 12 cm and a width of 8 cm.If you increase both the length and width by 3 cm, what will be the new area of the rectangle?Calculate the original area and the new area.How much does the area increase? can  u help me with this\n"},{"name":"stdout","text":"Tutor:  ok, so you know the length and the width of the rectangle already, right? now can we use that to calculate the original area of the rectangle\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  originial area is 12*8=96\n"},{"name":"stdout","text":"Tutor:  Hi there please recheck this\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  length is 12 and width is 8 so area is 96 \n"},{"name":"stdout","text":"Tutor:  right\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  and since length and breadth are increased by 3 length is 15 and width is 11 so area is 165\n"},{"name":"stdout","text":"Tutor:  you are absolutely right.the correct area is 165.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  original area was 96 new area is 165 so the area has increased by 165-96 that is 69\n"},{"name":"stdout","text":"Tutor:  i am glad we agree\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  i think i solved it\n"},{"name":"stdout","text":"Tutor:  Correct!\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  thanks for your help\n"},{"name":"stdout","text":"Tutor:  You're welcome\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  so what if i had to calculate the increase percentage in area?\n"},{"name":"stdout","text":"Tutor:  to calculate the increase percentage in area just remember that \n\noriginal area= length x breadth and new area= new length x new breadth \nin ur case new length is 15 new breadth is 11 and old length was 12 old breadth was 8 \n\nso new area is = 165 \nold area is 96 now subtract 96 from 165=169 which was wrong \nthe right solution should be\nincreased length is 15 decreased breadth is 11  so increase is 3 -3 so now subtract the right difference. increased width 11 decreased breadth is 8 \nnew area - old area is = (15 * 11) -  (12*8) which is = 165-96=69 now subtract the right difference. decrease width is 11 - 8=3  increase length is 15- 12=3 so now subtract 3+3 =6  so now subtract this difference =69 -6 = 63 and divide by original area so that is (63 /96 ) = (63/96 ) x100 and that is = 6.56%\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  i think this is not right the increase in percentage will be increase in area / original area times 100\n"},{"name":"stdout","text":"Tutor:  correct  increase in percentage in area will be  (  69 / 96 )*100  = 71.25%\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  yeah that is correct what was your previous answer about\n"},{"name":"stdout","text":"Tutor:  I said the new area is 165 so area increase was 165 - 96 that is 69. So area increase was 69 /96 that is 72.72%\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  before that\n"},{"name":"stdout","text":"Tutor:  I said the increase in area is 69 and original area is 96 and increase percentage will be = 69/96 x100  it should be  72.25\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  right thanks\n"},{"name":"stdout","text":"Tutor:  ok so that will be (69/96)*100\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  yeah 72.25 % \n"},{"name":"stdout","text":"Tutor:  the increase percentage was 100 times 69 divided by 96 which is\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  71.825 %\n"},{"name":"stdout","text":"Tutor:  correct\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  thanks\n"},{"name":"stdout","text":"Tutor:  you are welcome\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Student:  \n"}],"execution_count":33},{"cell_type":"code","source":"!zip -r llama_3b_math_puzzle_tutor.zip /kaggle/working/llama_3b_math_puzzle_tutor\nfrom IPython.display import FileLink\nFileLink(r'llama_3b_math_puzzle_tutor.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T19:27:49.846460Z","iopub.execute_input":"2025-01-26T19:27:49.846758Z","iopub.status.idle":"2025-01-26T19:27:55.445377Z","shell.execute_reply.started":"2025-01-26T19:27:49.846736Z","shell.execute_reply":"2025-01-26T19:27:55.444370Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/llama_3b_math_puzzle_tutor/ (stored 0%)\n  adding: kaggle/working/llama_3b_math_puzzle_tutor/README.md (deflated 66%)\n  adding: kaggle/working/llama_3b_math_puzzle_tutor/tokenizer.json (deflated 85%)\n  adding: kaggle/working/llama_3b_math_puzzle_tutor/special_tokens_map.json (deflated 71%)\n  adding: kaggle/working/llama_3b_math_puzzle_tutor/adapter_config.json (deflated 56%)\n  adding: kaggle/working/llama_3b_math_puzzle_tutor/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/llama_3b_math_puzzle_tutor/tokenizer_config.json (deflated 94%)\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/llama_3b_math_puzzle_tutor.zip","text/html":"<a href='llama_3b_math_puzzle_tutor.zip' target='_blank'>llama_3b_math_puzzle_tutor.zip</a><br>"},"metadata":{}}],"execution_count":36}]}